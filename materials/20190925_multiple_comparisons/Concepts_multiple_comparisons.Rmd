---
title: "Multiple Comparisons (Sleuth3 Sections 6.3 and 6.4)"
date: "2019-09-25"
output:
  pdf_document:
    fig_height: 2.8
    fig_width: 6
  html_document:
    fig_height: 3
    fig_width: 5
  word_document:
    fig_height: 3
    fig_width: 5
header-includes:
  - \usepackage{booktabs}
geometry: margin=0.6in
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(cache = FALSE)
library(ggplot2)
library(readr)
library(dplyr)
library(gmodels)
```

### Example 1: Diet restriction and longevity in mice (Sleuth3 Case study 5.1.1)

Mice were randomly assigned to one of 6 treatment groups with different diets to investigate relationships between diet and lifetime.  The life span of each mouse was recorded in months.

1. \textbf{NP}: Mice ate as much as they wanted of standard food for lab mice
2. \textbf{N/N85}: Control group.  \textbf{N}: no intervention before weaning; ate as normal. \textbf{N85}: no intervention after weaning; fed weekly diet of 85kcal/week (standard diet for lab mice)
3. \textbf{N/R50}: \textbf{N}: no intervention before weaning. \textbf{R50}: after weaning, restricted diet of 50 kcal/week
4. \textbf{R/R50}: \textbf{R}: restricted diet of 50 kcal/week before weaning. \textbf{R50}: after weaning, restricted diet of 50 kcal/week
5. \textbf{N/R50 lopro}: \textbf{N}: no intervention before weaning. \textbf{R50}: after weaning, restricted diet of 50 kcal/week.  Dietary protein decreased with mouse age.
6. \textbf{N/R40}: \textbf{N}: no intervention before weaning. \textbf{R40}: after weaning, restricted diet of 40 kcal/week

Denote the mean life spans in the population of mice fed each of these diets under laboratory conditions by $\mu_1$ through $\mu_6$.

\textbf{Planned Comparisons:}  Before data were collected, researchers decided on the comparisons below:

\includegraphics[width=0.77\textwidth]{sleuth3_display53.png}

(a) Are the population mean lifetimes the same for the \textbf{N/N85} and \textbf{N/R50} groups?
    * Confidence interval for $\mu_2 - \mu_3$ or test of $H_0: \mu_2 = \mu_3$ vs $H_A: \mu_2 \neq \mu_3$.

(b) Are the population mean lifetimes the same for the \textbf{N/R50} and \textbf{R/R50} groups?
    * Confidence interval for $\mu_3 - \mu_4$ or test of $H_0: \mu_3 = \mu_4$ vs $H_A: \mu_3 \neq \mu_4$.

(c) Are the population mean lifetimes the same for the \textbf{N/R50} and \textbf{N/R40} groups?
    * Confidence interval for $\mu_3 - \mu_6$ or test of $H_0: \mu_3 = \mu_6$ vs $H_A: \mu_3 \neq \mu_6$.

(d) Are the population mean lifetimes the same for the \textbf{N/R50} and \textbf{N/R50} lopro groups?
    * Confidence interval for $\mu_3 - \mu_5$ or test of $H_0: \mu_3 = \mu_5$ vs $H_A: \mu_3 \neq \mu_5$.

(e) Are the population mean lifetimes the same for the \textbf{N/N85} and \textbf{NP} groups?
    * Confidence interval for $\mu_2 - \mu_1$ or test of $H_0: \mu_2 = \mu_1$ vs $H_A: \mu_2 \neq \mu_1$

### Example 2: Handicaps and hiring (Sleuth3 Case Study 6.1.1 in Sleuth 3)

A 1990 study conducted a randomized experiment to explore how physical handicaps affect people's perception of employment qualifications.  The researchers prepared five videotaped job interviews using the same two male actors for each.  A set script was designed to reflect an interview with an applicant of average qualifications.  The videos differed only in that the applicant appeared with a different handicap:

 1. in one, he appeared to have no handicap;
 2. in a second, he appeared to have one leg amputated;
 3. in a third, he appeared on crutches;
 4. in a fourth, he appeared to have impaired hearing;
 5. and in a fifth, he appeared in a wheelchair.

Seventy undergraduate students from a US university were randomly assigned to view the videos, fourteen to each video.  After viewing ther video, each subject rated the qualifications of the applicant on a 0 to 10 point applicant qualification scale.

Denote by $\mu_1$ through $\mu_5$ the mean qualification score in the population of ratings that might be given by US undergraduate students from the US university in this study for each of the 5 handicaps groups.

\textbf{"Unplanned" Comparisons}: Maybe we want to compare the mean qualification score for every pair of groups

* Confidence interval for $\mu_1 - \mu_2$ or test of $H_0: \mu_1 = \mu_2$ vs $H_A: \mu_1 \neq \mu_2$

* Confidence interval for $\mu_1 - \mu_3$ or test of $H_0: \mu_1 = \mu_3$ vs $H_A: \mu_1 \neq \mu_3$

* Confidence interval for $\mu_1 - \mu_4$ or test of $H_0: \mu_1 = \mu_4$ vs $H_A: \mu_1 \neq \mu_4$

* Confidence interval for $\mu_1 - \mu_5$ or test of $H_0: \mu_1 = \mu_5$ vs $H_A: \mu_1 \neq \mu_5$

* Confidence interval for $\mu_2 - \mu_3$ or test of $H_0: \mu_2 = \mu_3$ vs $H_A: \mu_2 \neq \mu_3$

* Confidence interval for $\mu_2 - \mu_4$ or test of $H_0: \mu_2 = \mu_4$ vs $H_A: \mu_2 \neq \mu_4$

* Confidence interval for $\mu_2 - \mu_5$ or test of $H_0: \mu_2 = \mu_5$ vs $H_A: \mu_2 \neq \mu_5$

* Confidence interval for $\mu_3 - \mu_4$ or test of $H_0: \mu_3 = \mu_4$ vs $H_A: \mu_3 \neq \mu_4$

* Confidence interval for $\mu_3 - \mu_5$ or test of $H_0: \mu_3 = \mu_5$ vs $H_A: \mu_3 \neq \mu_5$

* Confidence interval for $\mu_4 - \mu_5$ or test of $H_0: \mu_4 = \mu_5$ vs $H_A: \mu_4 \neq \mu_5$

There are 10 different comparisons to do.

## Individual Confidence Level vs. Familywise Confidence Level

 * Individual confidence level: the proportion of samples for which a single confidence interval contains the parameter it is estimating
 
 * Familywise confidence level: the proportion of samples for which every one of several different confidence intervals contain the parameters they are estimating

\newpage

### Example (simulation study)

Suppose I have 5 groups with means $\mu_1 = 1$, $\mu_2 = 2$, $\mu_3 = 3$, $\mu_4 = 4$, $\mu_5 = 5$ and standard deviation $\sigma = 1$.

```{r, echo = FALSE, fig.height = 1.25}
x_grid <- seq(from = -2, to = 8, length = 101)
group_sd <- 1

plot_df <- data.frame(
  x = rep(x_grid, 5),
  y = c(dnorm(x_grid, mean = 1, sd = group_sd),
        dnorm(x_grid, mean = 2, sd = group_sd),
        dnorm(x_grid, mean = 3, sd = group_sd),
        dnorm(x_grid, mean = 4, sd = group_sd),
        dnorm(x_grid, mean = 5, sd = group_sd)),
  group = rep(c("Group 1: mean = 1, sd = 1", "Group 2: mean = 2, sd = 1", "Group 3: mean = 3, sd = 1", "Group 4: mean = 4, sd = 1", "Group 5: mean = 5, sd = 1"),
    each = length(x_grid))
)

ggplot(data = plot_df, mapping = aes(x = x, y = y, color = group)) +
  geom_line() +
  theme_bw()
```

\textbf{Results for 1 simulation}

 * Simulated a data set with 100 observations from each of the 5 groups
 * Calculated 95% confidence intervals for differences in group means, for each pair of means (10 intervals total)

\begin{table}[!h]
\centering
\begin{tabular}{c c c c c}
\toprule
Groups & Difference in Means & 95\% CI lower bound & 95\% CI upper bound & Contains true difference? \\
\toprule
2, 1 & 2 - 1 = 1 & 0.99 & 1.54 & Yes \\
\midrule
3, 1 & 3 - 1 = 2 & 1.60 & 2.16 & Yes \\
\midrule
4, 1 & 4 - 1 = 3 & 2.87 & 3.42 & Yes \\
\midrule
5, 1 & 5 - 1 = 4 & 3.55 & 4.10 & Yes \\
\midrule
3, 2 & 3 - 2 = 1 & 0.34 & 0.89 & No \\
\midrule
4, 2 & 4 - 2 = 2 & 1.60 & 2.15 & Yes \\
\midrule
5, 2 & 5 - 2 = 3 & 2.28 & 2.84 & No \\
\midrule
4, 3 & 4 - 3 = 1 & 0.99 & 1.54 & Yes \\
\midrule
5, 3 & 5 - 3 = 2 & 1.67 & 2.22 & Yes \\
\midrule
5, 4 & 5 - 4 = 1 & 0.41 & 0.96 & No \\
\bottomrule
\end{tabular}
\end{table}

For this particular sample, 7 out of 10 of the confidence intervals contain the difference in means they are estimating.

\textbf{Repeated for 1000 simulations:}

 * Repeated the process above for 1000 different simulated data sets.  Table shows:
    * percent of samples for which each CI comparing 2 groups succeded
    * percent of samples for which all 10 CIs succeeded

\begin{table}[!h]
\centering
\begin{tabular}{r l}
\toprule
Groups & Percent of Samples Successful \\
\toprule
2, 1 & 95.1\% \\
\midrule
3, 1 & 94.5\% \\
\midrule
4, 1 & 95.0\% \\
\midrule
5, 1 & 94.5\% \\
\midrule
3, 2 & 95.5\% \\
\midrule
4, 2 & 95.1\% \\
\midrule
5, 2 & 94.8\% \\
\midrule
4, 3 & 94.9\% \\
\midrule
5, 3 & 95.7\% \\
\midrule
5, 4 & 94.4\%\\
\midrule
All 10 comparisons & 71.1\% \\
\bottomrule
\end{tabular}
\end{table}

#### Basic idea: Make individual confidence levels larger to get desired familywise confidence level.

\newpage

#### Bonferroni adjustment

 * Intuition with 10 intervals:
    * Familywise confidence level 95%: for 95% of samples, all 10 intervals should simultaneously contain the parameter they are estimating.
    * For 5% of samples, at least one of the 10 does not contain the parameter it is estimating
    * Each individual CI misses for 0.5% of samples
    * Each individual CI has confidence level 99.5%

\begin{table}[!h]
\centering
\begin{tabular}{r c c}
\toprule
 & Target Percent of Samples Successful & Target Percent of Samples UNSuccessful \\
Groups & (Confidence Level) & (100 - Confidence Level) \\
\toprule
2, 1 &   &  \\
\midrule
3, 1 &   &  \\
\midrule
4, 1 &   &  \\
\midrule
5, 1 &   &  \\
\midrule
3, 2 &   &  \\
\midrule
4, 2 &   &  \\
\midrule
5, 2 &   &  \\
\midrule
4, 3 &   &  \\
\midrule
5, 3 &   &  \\
\midrule
5, 4 &   &  \\
\midrule
All 10 comparisons & 95\% ($1 - \alpha = 0.95$) &  \\
\bottomrule
\end{tabular}
\end{table}

#### Reminder of procedure for an individual confidence interval

 * In this class, all confidence intervals are calculated as $\text{Estimate} \pm \text{Multiplier} \times SE(\text{Estimate})$
 * So far, the Multiplier is $t_{df}(1 - \alpha/2)$.  Example: for a 95% CI, $\alpha = 0.05$, and $1 - \alpha/2 = 0.975$

```{r, fig.height = 2, echo = FALSE}
normal_mean <- 0
offset <- qt(0.975, df = 10)
lower <- -5
upper <- 5

plot_df1 <- data.frame(
  x = c(lower,
    seq(from = lower,
      to = normal_mean - offset,
      length = 101),
    normal_mean - offset
    ),
  density = c(0,
    dt(seq(from = lower,
        to = normal_mean - offset,
        length = 101),
      df = 10),
    0)
  )

plot_df2 <- data.frame(
  x = c(upper,
    seq(from = upper,
      to = normal_mean + offset,
      length = 101),
    normal_mean + offset
    ),
  density = c(0,
    dt(seq(from = upper,
        to = normal_mean + offset,
        length = 101),
      df = 10),
    0)
  )


ggplot(mapping = aes(x = c(lower, upper))) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df1) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df2) +
  stat_function(fun = dt, args = list(df = 10)) + 
  geom_vline(mapping = aes(xintercept = c(-1*offset, offset))) +
  geom_label(mapping = aes(
    x = c(-4.5, 0, 4.5),
    y = c(0.15, 0.15, 0.15),
    label = c("Shaded\nArea\n0.025", "Central\nArea\n0.95", "Shaded\nArea\n0.025")
  )) +
  xlab("") +
  ggtitle(
    expression(paste("Example with ", alpha, " = 0.05 (95% individual CI)")),
    subtitle = "Total area to left of t* is 0.975") +
  scale_x_continuous(name = "",
    breaks = c(lower, -offset, 0, offset, upper),
    labels = c(lower, expression(paste(-t, "*")), 0, expression(paste(t, "*")), upper)) +
  theme_bw()
```

#### Individual intervals have higher confidence levels to get desired familywise confidence level

 * In general, if there are $k$ confidence intervals to compute, use $\text{Multiplier} = t_{df}(1 - \alpha/2k)$

```{r, fig.height = 2, echo = FALSE}
normal_mean <- 0
offset <- qt(0.9975, df = 10)
lower <- -5
upper <- 5

plot_df1 <- data.frame(
  x = c(lower,
    seq(from = lower,
      to = normal_mean - offset,
      length = 101),
    normal_mean - offset
    ),
  density = c(0,
    dt(seq(from = lower,
        to = normal_mean - offset,
        length = 101),
      df = 10),
    0)
  )

plot_df2 <- data.frame(
  x = c(upper,
    seq(from = upper,
      to = normal_mean + offset,
      length = 101),
    normal_mean + offset
    ),
  density = c(0,
    dt(seq(from = upper,
        to = normal_mean + offset,
        length = 101),
      df = 10),
    0)
  )

ggplot(mapping = aes(x = c(lower, upper))) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df1) +
  geom_polygon(aes(x = x, y = density), fill = "black", alpha = 0.4, data = plot_df2) +
  stat_function(fun = dt, args = list(df = 10)) + 
  geom_vline(mapping = aes(xintercept = c(-1*offset, offset))) +
  geom_label(mapping = aes(
    x = c(-4.5, 0, 4.5),
    y = c(0.15, 0.15, 0.15),
    label = c("Shaded\nArea\n0.0025", "Central\nArea\n0.995", "Shaded\nArea\n0.0025")
  )) +
  xlab("") +
  ggtitle(
    expression(paste("Example with ", alpha, " = 0.05 (95% familywise CI)")),
    subtitle = "Total area to left of t* is 1 - 0.05/(2 * 10) = 0.9975") +
  scale_x_continuous(name = "",
    breaks = c(lower, -offset, 0, offset, upper),
    labels = c(lower, expression(paste(-t, "*")), 0, expression(paste(t, "*")), upper)) +
  theme_bw()
```

\newpage

#### Scheffe adjustment

 * Use $\text{Multiplier} = \sqrt{(I - 1) F_{(I-1),(n - 1)}(1 - \alpha)}$
 * Generally a larger multiplier (wider CIs) than the Bonferroni adjustment
 * Works for familywise inferences about every possible linear combination of group means $\gamma = C_1 \mu_1 + \cdots + C_I \mu_I$
    * (Doesn't matter how many!  Same adjustment for any number of intervals in the family!)
 * Usually not useful for ANOVA, but very useful for regression models, coming soon!

#### All 10 CIs plotted for each method

```{r, message = FALSE, echo = FALSE}
handicaps <- read_csv("http://www.evanlray.com/data/sleuth3/ex0601_handicaps.csv") %>%
  mutate(
    Handicap = factor(Handicap, levels = c("None", "Amputee", "Crutches", "Hearing", "Wheelchair"))
  )
anova_fit <- lm(Score ~ Handicap, data = handicaps)
```

```{r, echo = FALSE, warning=FALSE, fig.height = 2.65, fig.width = 7.5}
handicap_levels <- levels(handicaps$Handicap)

ci_results <- data.frame(
  ci_lower = vector("numeric", 30),
  ci_upper = vector("numeric", 30),
  ci_type = vector("character", 30),
  difference = vector("character", 30),
  stringsAsFactors = FALSE
)

bonferroni_multiplier <- qt(0.9975, df = 70 - 5)
scheffe_multiplier <- sqrt((5 - 1) * qf(0.95, df1 = 5 - 1, df2 = 70 - 5))

results_ind <- 0

for(ind1 in 1:4) {
  for(ind2 in (ind1+1):5) {
    c_vec <- rep(0, 5)
    c_vec[ind1] <- -1
    c_vec[ind2] <- 1
    ci <- fit.contrast(anova_fit, "Handicap", c_vec, conf.int = 0.95)
    
    # standard method
    results_ind <- results_ind + 1
    ci_lower <- ci[1, 5]
    ci_upper <- ci[1, 6]
    ci_results[results_ind, "ci_lower"] <- ci_lower
    ci_results[results_ind, "ci_upper"] <- ci_upper
    ci_results[results_ind, "ci_type"] <- "95% Individual"
    ci_results[results_ind, "difference"] <- paste0(handicap_levels[ind2], " - ", handicap_levels[ind1])
    
    # bonferroni
    results_ind <- results_ind + 1
    est <- ci[1, 1]
    se <- ci[1, 2]
    ci_results[results_ind, "ci_lower"] <- est - bonferroni_multiplier * se
    ci_results[results_ind, "ci_upper"] <- est + bonferroni_multiplier * se
    ci_results[results_ind, "ci_type"] <- "95% Familywise,\nBonferroni"
    ci_results[results_ind, "difference"] <- paste0(handicap_levels[ind2], " - ", handicap_levels[ind1])
    
    # scheffe
    results_ind <- results_ind + 1
    est <- ci[1, 1]
    se <- ci[1, 2]
    ci_results[results_ind, "ci_lower"] <- est - scheffe_multiplier * se
    ci_results[results_ind, "ci_upper"] <- est + scheffe_multiplier * se
    ci_results[results_ind, "ci_type"] <- "95% Familywise,\nScheffe"
    ci_results[results_ind, "difference"] <- paste0(handicap_levels[ind2], " - ", handicap_levels[ind1])
  }
}

ci_results$ci_type <- factor(ci_results$ci_type, levels = c("95% Individual", "95% Familywise,\nBonferroni", "95% Familywise,\nScheffe"))

ggplot(data = ci_results) +
  geom_errorbar(mapping = aes(x = difference, ymin = ci_lower, ymax = ci_upper, color = ci_type),
    position = position_dodge()) +
  scale_color_discrete("CI Type") +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 50, hjust = 1))
```

\newpage

## Similar ideas for hypothesis tests

 * p-value = probability of obtaining a test statistic at least as extreme as the value of that statistic we got in our sample data, if $H_0$ is true **in a single test**

 * If $H_0$ is actually correct, 5% of samples will have a p-value < 0.05 **by definition of a p-value**.  Imagine we conduct 20 hypothesis tests:   (Source: xkcd)

\begin{center}
\includegraphics[height=8.5in]{xkcd_significant.png}
\end{center}

\newpage

 * We need to recalibrate how small a p-value must be to provide evidence against the null hypothesis.

\begin{table}[!h]
\centering
\begin{tabular}{p{1.7cm} p{3.5cm} p{4cm} p{5cm}}
\toprule
Individual $p$-value & Strength of evidence against $H_0$ (one test) & Compare to... & But, Repeated 10 times \\
\midrule
0.10 or less & Some evidence; not conclusive & Probability of 4 heads in a row is 0.0625 & Probability of 4 heads in a row at least once in 10 repetitions is 0.4755 \\
\midrule
0.05 or less & Moderate & Probability of 5 heads in a row is 0.03125 & Probability of 4 heads in a row at least once in 10 repetitions is 0.2720 \\
\midrule
0.01 or less & Strong & Probability of 7 heads in a row is 0.007813 & Probability of 7 heads in a row at least once in 10 repetitions is 0.0754 \\
\midrule
0.001 or less & Very strong evidence & Probability of 10 heads in a row is 0.0009766 & Probability of 10 heads in a row at least once in 10 repetitions is 0.00972 \\
\bottomrule
\end{tabular}
\end{table}

 * The chance of obtaining a small p-value in at least one of the tests is larger than the chance of obtaining a small p-value in a single test.

 * Roughly, if I conduct 10 tests a p-value of 0.001 for one of those tests provides the same amount of evidence against the null hypothesis as a p-value of 0.01 if I only did a single test.


#### A second idea (not perfect)

 * Conduct an F test of $H_0: \mu_1 = \mu_2 = \ldots = \mu_I$ vs $H_A:$ at least one mean is different from the others
    * If this F test gives strong evidence against the claim that all means are equal, proceed to look at individual results, typically using unadjusted intervals/p-values
    * If the F test doesn't give strong evidence against the claim that all means are qual, stop!  Even if some individual comparisons had small p-values, you're done.

## When to bother?

Opinions differ

 * Book says:
    * if tests are "planned", no need to adjust for multiple comparisons
    * if tests are "unplanned", adjust
 * Some people say you should always adjust for multiple comparisons
 * I say you need to understand the issues and report what you are doing:
    * **Familywise confidence levels can be much less than individual confidence levels**
    * **Report whether or not you have adjusted for multiple comparisons**
    * **Report all confidence intervals/hypothesis tests you perform**, whether or not the results are "statistically significant" (p-value less than some threshold).  **Reporting only statistically significant results is cheating.**
    * To the extent possible, **plan your analysis before collecting data**, and keep number of planned comparisons small
